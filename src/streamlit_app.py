import asyncio
import os
from typing import AsyncGenerator, List

import streamlit as st
from streamlit.runtime.scriptrunner import get_script_run_ctx
from client import AgentClient
from schema import ChatMessage


# è¿™æ˜¯ä¸€ä¸ªç”¨äºé€šè¿‡ç®€å•èŠå¤©ç•Œé¢ä¸langgraphä»£ç†äº¤äº’çš„Streamlitåº”ç”¨ã€‚
# è¯¥åº”ç”¨æœ‰ä¸‰ä¸ªä¸»è¦çš„å¼‚æ­¥è¿è¡Œå‡½æ•°:

# - main() - è®¾ç½®streamlitåº”ç”¨å’Œé«˜å±‚ç»“æ„
# - draw_messages() - ç»˜åˆ¶ä¸€ç»„èŠå¤©æ¶ˆæ¯ - å¯ä»¥æ˜¯é‡æ”¾ç°æœ‰æ¶ˆæ¯
#   æˆ–æµå¼ä¼ è¾“æ–°æ¶ˆæ¯ã€‚
# - handle_feedback() - ç»˜åˆ¶åé¦ˆå°éƒ¨ä»¶å¹¶è®°å½•ç”¨æˆ·åé¦ˆã€‚

# è¯¥åº”ç”¨å¤§é‡ä½¿ç”¨AgentClientä¸ä»£ç†çš„FastAPIç«¯ç‚¹è¿›è¡Œäº¤äº’.


APP_TITLE = "Agent Service Toolkit"
APP_ICON = "ğŸ§°"


@st.cache_resource
def get_agent_client():
    agent_url = os.getenv("AGENT_URL", "http://localhost")
    return AgentClient(agent_url)


async def main():
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon=APP_ICON,
        menu_items={},
    )

    # Hide the streamlit upper-right chrome
    st.html(
        """
        <style>
        [data-testid="stStatusWidget"] {
                visibility: hidden;
                height: 0%;
                position: fixed;
            }
        </style>
        """,
    )
    if st.get_option("client.toolbarMode") != "minimal":
        st.set_option("client.toolbarMode", "minimal")
        await asyncio.sleep(0.1)
        st.rerun()

    models = {
        "OpenAI GPT-4o-mini (streaming)": "gpt-4o-mini",
        "Gemini 1.5 Flash (streaming)": "gemini-1.5-flash",
        "llama-3.1-70b on Groq": "llama-3.1-70b",
    }
    # Config options
    with st.sidebar:
        st.header(f"{APP_ICON} {APP_TITLE}")
        ""
        "Full toolkit for running an AI agent service built with LangGraph, FastAPI and Streamlit"
        with st.popover(":material/settings: Settings", use_container_width=True):
            m = st.radio("LLM to use", options=models.keys())
            model = models[m]
            use_streaming = st.toggle("Stream results", value=True)

        @st.dialog("Architecture")
        def architecture_dialog():
            st.image(
                "https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png?raw=true"
            )
            "[View full size on Github](https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png)"
            st.caption(
                "App hosted on [Streamlit Cloud](https://share.streamlit.io/) with FastAPI service running in [Azure](https://learn.microsoft.com/en-us/azure/app-service/)"
            )

        if st.button(":material/schema: Architecture", use_container_width=True):
            architecture_dialog()

        with st.popover(":material/policy: Privacy", use_container_width=True):
            st.write(
                "Prompts, responses and feedback in this app are anonymously recorded and saved to LangSmith for product evaluation and improvement purposes only."
            )

        "[View the source code](https://github.com/JoshuaC215/agent-service-toolkit)"
        st.caption(
            "Made with :material/favorite: by [Joshua](https://www.linkedin.com/in/joshua-k-carroll/) in Oakland"
        )

    # Draw existing messages
    if "messages" not in st.session_state:
        st.session_state.messages = []
    messages: List[ChatMessage] = st.session_state.messages

    if len(messages) == 0:
        WELCOME = "Hello! I'm an AI-powered research assistant with web search and a calculator. I may take a few seconds to boot up when you send your first message. Ask me anything!"
        with st.chat_message("ai"):
            st.write(WELCOME)

    # draw_messages() expects an async iterator over messages
    async def amessage_iter():
        for m in messages:
            yield m

    await draw_messages(amessage_iter())

    # Generate new message if the user provided new input
    if input := st.chat_input():
        messages.append(ChatMessage(type="human", content=input))
        st.chat_message("human").write(input)
        agent_client = get_agent_client()
        if use_streaming:
            stream = agent_client.astream(
                message=input,
                model=model,
                thread_id=get_script_run_ctx().session_id,
            )
            await draw_messages(stream, is_new=True)
        else:
            response = await agent_client.ainvoke(
                message=input,
                model=model,
                thread_id=get_script_run_ctx().session_id,
            )
            messages.append(response)
            st.chat_message("ai").write(response.content)
        st.rerun()  # Clear stale containers

    # If messages have been generated, show feedback widget
    if len(messages) > 0:
        with st.session_state.last_message:
            await handle_feedback()


async def draw_messages(
    messages_agen: AsyncGenerator[ChatMessage | str, None],
    is_new=False,
):
    """
    ç»˜åˆ¶ä¸€ç»„èŠå¤©æ¶ˆæ¯ - å¯ä»¥æ˜¯é‡æ”¾ç°æœ‰æ¶ˆæ¯æˆ–æµå¼ä¼ è¾“æ–°æ¶ˆæ¯ã€‚

    æ­¤å‡½æ•°æœ‰é¢å¤–çš„é€»è¾‘æ¥å¤„ç†æµå¼ä»¤ç‰Œå’Œå·¥å…·è°ƒç”¨ã€‚
    - ä½¿ç”¨å ä½å®¹å™¨æ¥æ¸²æŸ“åˆ°è¾¾çš„æµå¼ä»¤ç‰Œã€‚
    - ä½¿ç”¨çŠ¶æ€å®¹å™¨æ¥æ¸²æŸ“å·¥å…·è°ƒç”¨ã€‚è·Ÿè¸ªå·¥å…·è¾“å…¥å’Œè¾“å‡º
      å¹¶ç›¸åº”åœ°æ›´æ–°çŠ¶æ€å®¹å™¨ã€‚

    è¯¥å‡½æ•°è¿˜éœ€è¦åœ¨ä¼šè¯çŠ¶æ€ä¸­è·Ÿè¸ªæœ€åä¸€æ¡æ¶ˆæ¯å®¹å™¨,
    å› ä¸ºåç»­æ¶ˆæ¯å¯ä»¥ç»˜åˆ¶åˆ°åŒä¸€ä¸ªå®¹å™¨ä¸­ã€‚è¿™ä¹Ÿç”¨äº
    åœ¨æœ€æ–°çš„èŠå¤©æ¶ˆæ¯ä¸­ç»˜åˆ¶åé¦ˆå°éƒ¨ä»¶ã€‚

    å‚æ•°:
        messages_aiter: è¦ç»˜åˆ¶çš„æ¶ˆæ¯çš„å¼‚æ­¥è¿­ä»£å™¨ã€‚
        is_new: æ¶ˆæ¯æ˜¯å¦ä¸ºæ–°æ¶ˆæ¯ã€‚
    """

    # è·Ÿè¸ªæœ€åä¸€æ¡æ¶ˆæ¯å®¹å™¨
    last_message_type = None
    st.session_state.last_message = None

    # ç”¨äºä¸­é—´æµå¼ä»¤ç‰Œçš„å ä½ç¬¦
    streaming_content = ""
    streaming_placeholder = None

    # éå†æ¶ˆæ¯å¹¶ç»˜åˆ¶å®ƒä»¬
    while msg := await anext(messages_agen, None):
        # stræ¶ˆæ¯è¡¨ç¤ºæ­£åœ¨æµå¼ä¼ è¾“çš„ä¸­é—´ä»¤ç‰Œ
        if isinstance(msg, str):
            # å¦‚æœå ä½ç¬¦ä¸ºç©º,è¿™æ˜¯æ­£åœ¨æµå¼ä¼ è¾“çš„æ–°æ¶ˆæ¯çš„ç¬¬ä¸€ä¸ªä»¤ç‰Œã€‚æˆ‘ä»¬éœ€è¦è¿›è¡Œè®¾ç½®ã€‚
            if not streaming_placeholder:
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")
                with st.session_state.last_message:
                    streaming_placeholder = st.empty()

            streaming_content += msg
            streaming_placeholder.write(streaming_content)
            continue
        if not isinstance(msg, ChatMessage):
            st.error(f"æ„å¤–çš„æ¶ˆæ¯ç±»å‹: {type(msg)}")
            st.write(msg)
            st.stop()
        match msg.type:
            # æ¥è‡ªç”¨æˆ·çš„æ¶ˆæ¯,æœ€ç®€å•çš„æƒ…å†µ
            case "human":
                last_message_type = "human"
                st.chat_message("human").write(msg.content)

            # æ¥è‡ªä»£ç†çš„æ¶ˆæ¯æ˜¯æœ€å¤æ‚çš„æƒ…å†µ,å› ä¸ºæˆ‘ä»¬éœ€è¦
            # å¤„ç†æµå¼ä»¤ç‰Œå’Œå·¥å…·è°ƒç”¨ã€‚
            case "ai":
                # å¦‚æœæˆ‘ä»¬æ­£åœ¨æ¸²æŸ“æ–°æ¶ˆæ¯,å°†æ¶ˆæ¯å­˜å‚¨åœ¨ä¼šè¯çŠ¶æ€ä¸­
                if is_new:
                    st.session_state.messages.append(msg)

                # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯ç±»å‹ä¸æ˜¯AI,åˆ›å»ºä¸€ä¸ªæ–°çš„èŠå¤©æ¶ˆæ¯
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")

                with st.session_state.last_message:
                    # å¦‚æœæ¶ˆæ¯æœ‰å†…å®¹,å°†å…¶å†™å‡ºã€‚
                    # é‡ç½®æµå¼å˜é‡ä»¥å‡†å¤‡ä¸‹ä¸€æ¡æ¶ˆæ¯ã€‚
                    if msg.content:
                        if streaming_placeholder:
                            streaming_placeholder.write(msg.content)
                            streaming_content = ""
                            streaming_placeholder = None
                        else:
                            st.write(msg.content)

                    if msg.tool_calls:
                        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨åˆ›å»ºä¸€ä¸ªçŠ¶æ€å®¹å™¨,å¹¶æŒ‰IDå­˜å‚¨
                        # çŠ¶æ€å®¹å™¨,ä»¥ç¡®ä¿ç»“æœæ˜ å°„åˆ°æ­£ç¡®çš„çŠ¶æ€å®¹å™¨ã€‚
                        call_results = {}
                        for tool_call in msg.tool_calls:
                            status = st.status(
                                f"""å·¥å…·è°ƒç”¨: {tool_call["name"]}""",
                                state="running" if is_new else "complete",
                            )
                            call_results[tool_call["id"]] = status
                            status.write("è¾“å…¥:")
                            status.write(tool_call["args"])

                        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨æœŸæœ›ä¸€ä¸ªToolMessageã€‚
                        for _ in range(len(call_results)):
                            tool_result: ChatMessage = await anext(messages_agen)
                            if not tool_result.type == "tool":
                                st.error(f"æ„å¤–çš„ChatMessageç±»å‹: {tool_result.type}")
                                st.write(tool_result)
                                st.stop()

                            # å¦‚æœæ˜¯æ–°æ¶ˆæ¯,è®°å½•æ¶ˆæ¯,å¹¶ç”¨ç»“æœæ›´æ–°æ­£ç¡®çš„
                            # çŠ¶æ€å®¹å™¨
                            if is_new:
                                st.session_state.messages.append(tool_result)
                            status = call_results[tool_result.tool_call_id]
                            status.write("è¾“å‡º:")
                            status.write(tool_result.content)
                            status.update(state="complete")

            # å¦‚æœé‡åˆ°æ„å¤–çš„æ¶ˆæ¯ç±»å‹,è®°å½•é”™è¯¯å¹¶åœæ­¢
            case _:
                st.error(f"æ„å¤–çš„ChatMessageç±»å‹: {msg.type}")
                st.write(msg)
                st.stop()


async def handle_feedback():
    """ç»˜åˆ¶åé¦ˆå°éƒ¨ä»¶å¹¶è®°å½•ç”¨æˆ·åé¦ˆã€‚"""

    # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ
    env = os.getenv("ENV", "development")
    if env == "production":
        # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¦ç”¨åé¦ˆåŠŸèƒ½
        return

    # Keep track of last feedback sent to avoid sending duplicates
    if "last_feedback" not in st.session_state:
        st.session_state.last_feedback = (None, None)

    latest_run_id = st.session_state.messages[-1].run_id
    feedback = st.feedback("stars", key=latest_run_id)

    # If the feedback value or run ID has changed, send a new feedback record
    if feedback is not None and (latest_run_id, feedback) != st.session_state.last_feedback:
        # Normalize the feedback value (an index) to a score between 0 and 1
        normalized_score = (feedback + 1) / 5.0

        agent_client = get_agent_client()
        await agent_client.acreate_feedback(
            run_id=latest_run_id,
            key="human-feedback-stars",
            score=normalized_score,
            kwargs=dict(
                comment="In-line human feedback",
            ),
        )
        st.session_state.last_feedback = (latest_run_id, feedback)
        st.toast("Feedback recorded", icon=":material/reviews:")


if __name__ == "__main__":
    asyncio.run(main())